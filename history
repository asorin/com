#process data with 4 threads, 10 random trials
tools/process.sh southern/southern norm2max 1 10 4

#aggregate modularity
cat `tools/aggregate.py modularity lastfm users_tags norm2max`

#audioscrobbler filtering of data
cat user_artist.dat | awk '($1<=1000300){print $0}' > user_artist_ku.dat

#convert graph to gml
bin/dcom -l data/southern/southern_tfidf.dat  -o data/southern/southern_tfidf.gml -a save

#add tfidf weights
bin/dcom -l data/southern/southern.dat -o data/southern/southern_tfidf.dat -a transform

#run clustering configuration
bin/dcom -c conf/clustering.yml -l data/twitter_elections/users_domains_50k.dat -o data/twitter_elections/output/output_users_domains_50k_clustering.csv

# get list of all object degrees
cat data/delicious/users_tags_1ku.dat | awk -F"\t" '{print $2}' | sort -n | uniq -c | awk '{print $1}' > data/delicious/users_tags_1ku_degrees.dat

# fit distribution to degrees of nodes (1 or 2)
tools/degreedist.sh lastfm/users_tags 2

# convert ground truth communities to used format
tools/groundconvert.py data/twitter_userlists/politicsie.communities data/twitter_politicsie/politicsie.communities.ground data/twitter_politicsie/users.dat

# show mutual information
for i in `find data/twitter_politicsie/validate -name "*.mutual" | sort`; do echo $i `cat $i`; done

# get results from comparison between colisted and tfidf
for i in `find data/twitter_rugby/validate -name "*.mutual" | sort`; do path=`echo $i | awk -F"mutual" '{print $1}'`; name=`echo $path | awk -F"/" '{print $(NF-1)"/"$(NF)}'`; thr=`echo $name | awk -F"_" '{print $NF}'`; echo $name $thr `wc -l ${path}dat| cut -d ' ' -f1` `cat $i`; done

# validate tfidf by comparing to colisted score
tools/process_validate.sh twitter_rugby/rugby

# partition network using SVD
bin/dcom -l data/twitter_politicsie/politicsie.dat -o data/twitter_politicsie/politicsie.communities.svd -a partition-svd -nc 7 -nt 0

bin/dcom -l data/twitter_politicsuk/politicsuk.dat -o data/twitter_politicsuk/politicsuk.communities.svd -a partition-svd -nc 2 -nt 0
